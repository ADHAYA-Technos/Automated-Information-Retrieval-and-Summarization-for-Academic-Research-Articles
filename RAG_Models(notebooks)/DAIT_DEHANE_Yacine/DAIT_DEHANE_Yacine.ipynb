{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Approch for summerazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Libraries\n",
    "import os\n",
    "import chromadb\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PDF_PATH = r\"D:\\2CSI-Project\\PDFs_papers\"  # Folder containing PDFs\n",
    "CHUNKS_DIR = r\"D:\\2CSI-Project\\Chunks\"  # Folder to store chunks\n",
    "PROGRESS_FILE = r\"D:\\2CSI-Project\\progress.txt\"  # File to save the last processed index\n",
    "VECTORDB_PATH = r\"D:\\2CSI-Project\\VectorDB_Embeddings\"\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "os.makedirs(CHUNKS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chroma DB Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient(path=VECTORDB_PATH)\n",
    "collection = client.get_or_create_collection(name='ties_collection_emb', metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Laod Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query & query embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"cademic community. As an illustration of the scale of the field’s growth, the number of submis-\n",
    "sions to NeurIPS, a primary conference on ML methods, has quadrupled in six years, going from\n",
    "1,678submissionsin2014to6,743in2019[ 38].Nevertheless,therearestillplentyofpracticalcon-\n",
    "siderationsthataffectthemodellearningstage.Inthissection,wediscussissuesconcerningthree\n",
    "steps within model learning: model selection, training, and hyper-parameter selection.\n",
    "4.1 Model Selection\n",
    "In many practical cases the selection of a model is decided by one key characteristic of a model:\n",
    "complexity.Despiteareassuchasdeeplearningandreinforcementlearninggaininginpopularity\n",
    "with the research community, in practice simpler models are often chosen. Such models include\n",
    "shallowneuralnetworkarchitectures,simpleapproachesbasedon PrincipalComponentAnal-\n",
    "ysis (PCA), decision trees, and random forests.\n",
    "Simple models can be used as a way to prove the concept of the proposed ML solution and get\n",
    "the end-to-end setup in place. This approach reduces the time to get a deployed solution, allows\n",
    "the collection of important feedback, and also helps avoid overcomplicated designs. This was the\n",
    "case reported by Haldar et al. [39]. In the process of applying machine learning to AirBnB search,\n",
    "the team started with a complex deep learning model. The team was quickly overwhelmed by its\n",
    "complexityandendedupconsumingdevelopmentcycles.Afterseveralfaileddeploymentattempts\n",
    "the neural network architecture was drastically simplified: a single hidden layer NN with 32 fully\n",
    "connected ReLU activations. Even such a simple model had value, as it allowed the building of a\n",
    "whole pipeline of deploying ML models\"\"\"\n",
    "query_embedding = embedding_model.encode(query).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve most similiar chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=5,\n",
    "    include=[\"documents\", \"distances\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: academic community. As an illustration of the scale of the field’s growth, the number of submis-\n",
      "sions to NeurIPS, a primary conference on ML methods, has quadrupled in six years, going from\n",
      "1,678submissionsin2014to6,743in2019[ 38].Nevertheless,therearestillplentyofpracticalcon-\n",
      "siderationsthataffectthemodellearningstage.Inthissection,wediscussissuesconcerningthree\n",
      "steps within model learning: model selection, training, and hyper-parameter selection.\n",
      "4.1 Model Selection\n",
      "In many practical cases the selection of a model is decided by one key characteristic of a model:\n",
      "complexity.Despiteareassuchasdeeplearningandreinforcementlearninggaininginpopularity\n",
      "with the research community, in practice simpler models are often chosen. Such models include\n",
      "shallowneuralnetworkarchitectures,simpleapproachesbasedon PrincipalComponentAnal-\n",
      "ysis (PCA), decision trees, and random forests.\n",
      "Simple models can be used as a way to prove the concept of the proposed ML solution and get\n",
      "the end-to-end setup in place. This approach reduces the time to get a deployed solution, allows\n",
      "the collection of important feedback, and also helps avoid overcomplicated designs. This was the\n",
      "case reported by Haldar et al. [39]. In the process of applying machine learning to AirBnB search,\n",
      "the team started with a complex deep learning model. The team was quickly overwhelmed by its\n",
      "complexityandendedupconsumingdevelopmentcycles.Afterseveralfaileddeploymentattempts\n",
      "the neural network architecture was drastically simplified: a single hidden layer NN with 32 fully\n",
      "connected ReLU activations. Even such a simple model had value, as it allowed the building of a\n",
      "whole pipeline of deploying ML models in a production setting, while providing reasonably good\n",
      "performance.4 Over time the model evolved, with a second hidden layer being added, but it still\n",
      "remained fairly simple, never reaching the initially intended level of complexity.\n",
      "3For further discussion of the role user interface can play in adoption of an ML system, see Section7.3.\n",
      "4We discuss more benefits of setting up the automated deployment pipeline in Section6.3.\n",
      "ACM Computing Surveys, Vol. 55, No. 6, Article 114. Publication date: December 2022.114:8 A. Paleyes et al.\n",
      "Another advantage that less complex models can offer is their relatively modest hardware re-\n",
      "quirements. This becomes a key decision point in resource-constrained environments, as shown\n",
      "by Wagstaff et al. [40]. They worked on deploying ML models to a range of scientific instruments\n",
      "onboard the Europa Clipper spacecraft. Spacecraft design is always a tradeoff between the to-\n",
      "tal weight, robustness, and the number of scientific tools onboard. Therefore, computational re-\n",
      "sourcesarescarceandtheirusagehastobeassmallaspossible.Theserequirementsnaturallyfavor\n",
      "the models that are light on computational demands. The team behind Europa Clipper used ma-\n",
      "chine learning for three anomaly detection tasks; some models took time series data as input and\n",
      "some models took images, and on all three occasions simple threshold or PCA-based techniques\n",
      "were implemented. They were specifically chosen because of their robust performance and low\n",
      "demand for computational power.\n",
      "A further example of a resource-constrained environment is wireless cellular networks, where\n",
      "energy,memoryconsumption,anddatatransmissionareverylimited.Mostadvancedtechniques,\n",
      "suchasdeeplearning,arenotconsideredyetforpracticaldeployment,despitebeingabletohandle\n",
      "high-dimensional mobile network data [41].\n",
      "Similarity Score: 0.9680073261260986\n",
      "================================================================================\n",
      "Chunk: complexity and performance on the training dataset), and Resampling \n",
      "techniques (using approaches such as cross -validation). Hyperparameter \n",
      "selection is another category of model selection. This category comprises \n",
      "certain techniques that are used to search for the best hyperparameters \n",
      "settings, such as: Grid Search (searching the best hyperparameters using a \n",
      "grid of specified parameter values ); random search  (seeking the model \n",
      "with the optimal hyperparameters in a valid search space using a specified \n",
      "number of trials ); evolutionary algorithms  (finding optimal \n",
      "hyperparameters using heuristic-based approach es); and Bayesian  \n",
      "optimization (a probabilistic model used for hyperparameters tuning). \n",
      "(iv) Model Evaluation: as discussed previously, the optimal predictive model \n",
      "is selected using various selection techniques, in which the performance \n",
      "can be measured on the training dataset. Yet, to study how the model \n",
      "generalizes on unseen dataset is another important consideration. This is a \n",
      "decisive step in the predictive modeling framework as it creates venues for \n",
      "continuous improvements on the implemented approach. In fact, building \n",
      "a robust predictive model is  not a trivial task; it entails carrying out solid6 \n",
      "measures to quantify its effectiveness and accuracy. There are several \n",
      "metrics that can be used to evaluate the performance of a machine learning \n",
      "model. These measures can be mainly classified to two categories: \n",
      "Regression metrics and Classification metrics. Regression metrics include \n",
      "measures such: RMSE (Root Mean Square Error), MAE (Mean Absolute \n",
      "Error), R Squared (R²) and Adjusted R Squared . Classification metrics \n",
      "embody certain well-known metrics such as: Precision, Recall,  F1 Score \n",
      "Accuracy, ROC, AUC, Log-Loss etc.  \n",
      "Stage 4- Integration and Visualization: Business Intelligence applications are \n",
      "designed mainly to process and manipulate structured data stored in data \n",
      "warehouses. Therefore, another significant task of predictive modeling framework \n",
      "is to articulate structure from unstructured input data. In thi s context, the data \n",
      "structuring process incorporate s semantic analysis so as to provide a better \n",
      "understanding of the schema structure of data warehouses. Thus, the next process \n",
      "will migrate these data with the data coming from the ETL (Extract, Transform and \n",
      "Load) process to produce integrated, meaningful, and trustworthy structured data to \n",
      "load into the integrated data warehouse. This integration of traditional business \n",
      "intelligence and social business intelligence will enhance the quality of reports \n",
      "extracted by BI tools, thus achieving an additional objective of the overall \n",
      "framework.7 \n",
      " \n",
      "Figure 1: Predictive Analytics Framework for Social Big Data8 \n",
      " \n",
      "5.3 Machine learning algorithms for SBD \n",
      "predictive analytics \n",
      "In this section, we discuss several commonly used machine learning algorithms \n",
      "to develop a predictive model, which predicts the new social situation, \n",
      "ˆy , when the \n",
      "prediction features , \n",
      "( )12, ,..., nx x x x= , are given. The predictive model can be  \n",
      "developed when a dataset which relating the prediction features and past social \n",
      "situation, \n",
      "y , is available, where \n",
      "n  is the number of prediction features. We discuss \n",
      "the following machine algorithms namely logistic regression (LR), generalized \n",
      "linear model, naïve bayes (NB), tree based classification, random forest , gradient \n",
      "boosted tree and deep learning: \n",
      "5.3.1 Logistic Regression \n",
      "Logistic regression is a statistical method which has commonly been us ing for\n",
      "Similarity Score: 0.6099194288253784\n",
      "================================================================================\n",
      "Chunk: Table 2: Quality measure of machine learning models\n",
      "Model Selection: There are plenty of ML models and introductory books on classical\n",
      "methods [45,79] and Deep Learning [72] can be used to compare and understand their char-\n",
      "acteristics. The model selection depends on the data and has to be tailored to the problem.\n",
      "There is no such model that performs the best on all problem classes (No Free Lunch Theorem\n",
      "for ML[80]). It is best practice to start with models of lower capacity, which can serve as\n",
      "baseline, and gradually increase the capacity. Validating each step assures its beneﬁt and avoid\n",
      "unnecessary complexity of the model.\n",
      "Incorporate domain knowledge:In practice, a specialized model for a speciﬁc task performs\n",
      "better than a general model for all possible tasks. However, adapting the model to a speciﬁc\n",
      "problem involves the risk of incorporating false assumption and could reduce the solution space\n",
      "to a non-optimal subset. Therefore, it is best practice to validate the incorporated domain\n",
      "knowledge in isolation against a baseline. Adding domain knowledge should always increase\n",
      "the quality of the model, otherwise, it should be removed to avoid false bias.\n",
      "Model training: The trained model depends on the learning problem and as such are\n",
      "tightly coupled. The learning problem contains anobjective, optimizer, regularization and\n",
      "cross-validation [45,72]. The objective of the learning problem depends on the application.\n",
      "Diﬀerent applications value diﬀerent aspects and have to be tweaked in alignment with the\n",
      "business success criteria. The objective is a proxy to evaluate the performance of the model.\n",
      "The optimizer deﬁnes the learning strategy and how to adapt the parameters of the model to\n",
      "improve the objective.Regularization which can be incorporated in the objective, optimizer\n",
      "and in the model itself is needed to reduce the risk of overﬁtting and can help to ﬁnd unique\n",
      "solutions. Cross-validation is performed for feature selection, to optimize the hyper-parameters\n",
      "of the model and to test its generalization property to unseen data [81]. Cross-validation11 of 20\n",
      "[45] is based on a splitting of historical data in training, validation and testing data, where\n",
      "the latter is used as a proxy for the target environment [82]. Frameworks such as Auto-ML\n",
      "[83,84] or Neural Architecture Search [85] enables to partly automatize the hyper-parameters\n",
      "optimization and the architecture search.\n",
      "Using unlabeled data and pre-trained models:Labeling data could be very expensive and\n",
      "might limit the available data set size. Unlabeled data might be exploited in the training\n",
      "process, e.g. by performing unsupervised pre-training [86,87] and semi-supervised learning\n",
      "algorithms [88,89]. Complementary,transfer learningcould be used to pre-train the network\n",
      "on a proxy data set (e.g. from simulations) that resembles the original data to extract common\n",
      "features [90].\n",
      "Model Compression:Compression or pruning methods could be used to obtain a more\n",
      "compact model. In kernel methods low rank approximations of the kernel matrix is an essential\n",
      "tool to tackle large scale learning problems [91,92]. Neural Networks use a diﬀerent approach\n",
      "[93] by either pruning the network weights [94] or applying a compression scheme on the\n",
      "network weights [95].\n",
      "Ensemble methods: Ensemble methods train multiple models to perform the decision\n",
      "based on the aggregate decisions of the individual models. The models could be of diﬀerent\n",
      "Similarity Score: 0.6066123843193054\n",
      "================================================================================\n",
      "Chunk: Empirical learning curves are grown iteratively for the whole set or shrink-\n",
      "ing subsets of it. Successive halving and related works are a prominent\n",
      "example of horizontal decision making (Van den Bosch, 2004; Jamieson\n",
      "and Talwalkar, 2016). However, these approaches only consider the last\n",
      "anchor point (rather than the complete learning curve).\n",
      "2. Vertical Model Selection. Vertical means that the set of learners is gener-\n",
      "ally not limited to a finite set, and the set of evaluated learner candidates\n",
      "evolves over time (i.e., not fixed apriori). Learners are evaluated one after\n",
      "another. Each learner is evaluated in an iterative fashion to grow a learn-\n",
      "ing curve and allow for early discarding. Examples are the early discarding\n",
      "routine for deep networks by Domhan et al (2015) or, more generally, for\n",
      "learning curve cross-validation (Mohr and van Rijn, 2021, 2023).\n",
      "3. Diagonal Model Selection. This case is similar to the vertical decision-\n",
      "making situation with the difference that one does allow to continue the\n",
      "evaluation of a candidate at a later point. Hence, candidates are not\n",
      "evaluated one after another, but the evaluation of different candidates\n",
      "can be interleaved. Examples are Bayesian optimisation-based approaches\n",
      "to pause and continue evaluations of (not necessarily iterative) learn-\n",
      "ers (Klein et al, 2017a; Swersky et al, 2014). Non-iterative learners must\n",
      "be trained from scratch with the increased budget.\n",
      "Another approach that addresses this type of decision-making situa-\n",
      "tion is Hyperband (Li et al, 2017) and Bayesian optimisation based on\n",
      "progressive sampling (Zeng and Luo, 2017). However, neither of these\n",
      "approaches considers learning curves even though they implicitly con-\n",
      "struct them. Decisions are taken based on the observations of the largest\n",
      "anchor point considered so far.Springer Nature 2021 LATEX template\n",
      "28 Learning Curves for Decision Making\n",
      "4.2 Technical Questions Asked About Learning Curves\n",
      "A plethora of questions can be asked about learning curves. Fig. 10 gives an\n",
      "overview of these questions. The figure is organised in three layers (depth\n",
      "dimension) corresponding to the three types of estimates discussed in Sec. 3.\n",
      "Each layer consists of a set of questions that can be posed about learning\n",
      "curves. From bottom to top, the questions are ordered by complexity, and\n",
      "an arrow from one question to another indicates that the question with the\n",
      "incoming arrow is more general. Answering the more general question also\n",
      "implies answering the less general question.\n",
      "In the simplest case, we can answer a binary question. There are four\n",
      "relevant questions, i.e., (i) whether some specific anchor point, e.g., the dataset\n",
      "size, is beyond the saturation point (bsat ≤ bref ), (ii) whether the performance\n",
      "of a learner at the saturation point is better than some baseline τ (psat ≤\n",
      "τ), (iii) whether the performance pref := C(a, bref ) at some reference point\n",
      "bref is better than some threshold τ, or (iv) whether a specific anchor point\n",
      "is beyond the utility-based stopping point ( bu\n",
      "sat < bref ). To our knowledge,\n",
      "the only approaches in this category are those implicitly answering question\n",
      "(iii) by discarding candidates that are not believed to be competitive (see,\n",
      "e.g., Jamieson and Talwalkar, 2016; Petrak, 2000; Zeng and Luo, 2017); here\n",
      "τ = min a∈A C(a, bref ) is the (unknown) best performance of any learner on\n",
      "the target size.\n",
      "Similarity Score: 0.6057322025299072\n",
      "================================================================================\n",
      "Chunk: applications of ML for SE in order to characterize the ob-\n",
      "tained articles into appropriate categories. We named the\n",
      "taxonomy as MLSE (machine learning for software engi-\n",
      "neering). The taxonomy was devised following the princi-\n",
      "ples mentioned in [51, 212]. As aforementioned, we have\n",
      "consultedtheknowledgeareasinSEfromtheSWEBOK[198]\n",
      "and envisioned a hierarchical-based classiﬁcation structure\n",
      "of the taxonomy. Each participant of the study analyzed the\n",
      "applicationsintheirassignedsetthearticlesandaggregated\n",
      "them based on the similarities as described in step 7 of Sec-\n",
      "tion 2.2. Subsequently, we have organized the applications\n",
      "of ML for SE as subbranches, which belong to ﬁve life cy-\n",
      "clestagesofSE(knowledgeareas). TheapplicationsofML\n",
      "for SE that come under corresponding SE life cycle stages\n",
      "along with the number of articles are brieﬂy explained be-\n",
      "low. Table 2 shows the corresponding articles with respect\n",
      "totheclassiﬁcationproposedasaMLSEtaxonomyasshown\n",
      "inFig. 5. Followingisa briefdescriptionof theelementsof\n",
      "the MLSE taxonomy:\n",
      "The Requirements stage comprises of three categories.\n",
      "• Requirements Modeling and Analysis (9 (4%) arti-\n",
      "cles): Requirement Modeling and Analysis contains\n",
      "articles that are focusing on distinguishing ambigu-\n",
      "ous requirements, resolving incompleteness, correct-\n",
      "ness of requirements, etc.\n",
      "Saad Shaﬁq et al.:Preprint submitted to Elsevier Page 5 of 20Machine Learning for Software Engineering: A Systematic Mapping\n",
      "Figure 3: Systematic Map - Association of Contribution/Research Facets with the SE Stage Facet\n",
      "Figure 4: Articles by SE life cycle Stages\n",
      "• RequirementsSelection/Prioritization/Classiﬁcation\n",
      "(6(3%)articles): RequirementsSelection/Prioritization/\n",
      "Classiﬁcation deals with articles proposing ML tech-\n",
      "niquesthatemphasizeonautomatingprioritizationof\n",
      "requirements or their classiﬁcation.\n",
      "• Requirements Traceability (6 (3%) articles):Re-\n",
      "quirements traceability contains articles that refer to\n",
      "theMLapproachesthatassistinlinkingrequirements\n",
      "to code or other artifacts.\n",
      "The Architecture and Design stage consists of three cat-\n",
      "egories.\n",
      "• Design Modeling (15 (7%) articles):Design Model-\n",
      "ing comprises of articles in which software process/\n",
      "servicesrecommendationmodelshavebeenproposed\n",
      "in order to facilitate the project managers in selection\n",
      "of the most suitable process model for their projects.\n",
      "Apart from this, model smells and re-factoring tech-\n",
      "niques of object-oriented structures using ML have\n",
      "also been proposed in the articles.\n",
      "• DesignPatternPrediction(4(2%)articles): Design\n",
      "Pattern Prediction comprises of articles that primar-\n",
      "ily focus on recognizing design patterns in software\n",
      "throughsourcecodeoruserinterfacelayoutusingML\n",
      "techniques.\n",
      "• Development Eﬀort Estimation (20 (9%) articles):\n",
      "Development Eﬀort Estimation refers to the eﬀort es-\n",
      "timation of software projects using ML techniques.\n",
      "The Implementation stage has four categories.\n",
      "• CodeClone/Localization/Re-factoring/Labelling(8\n",
      "(3%)articles): CodeClone/Localization/Re-factoring/\n",
      "Labellingcomprisesofarticlesthataimatﬁndingcode\n",
      "Similarity Score: 0.5926510691642761\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "## printing chunks\n",
    "for i in range(len(results[\"documents\"][0])):\n",
    "    print(f\"Chunk: {results['documents'][0][i]}\")\n",
    "    print(f\"Similarity Score: {1 - results['distances'][0][i]}\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEDS_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
